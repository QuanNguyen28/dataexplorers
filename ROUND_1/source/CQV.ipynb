{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from loader import train_loader, val_loader, test_loader, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# Positional Encoding (batch_first=True)\n",
    "##########################################\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "##########################################\n",
    "# Conditional Quantile VAE (CQuantVAE)\n",
    "##########################################\n",
    "class ConditionalQuantileVAE(nn.Module):\n",
    "    def __init__(self, window_size, num_series, static_dim,\n",
    "                 latent_dim=32, hidden_dim=128, dropout=0.1, output_dim=2, num_quantiles=3):\n",
    "        \"\"\"\n",
    "        window_size: số bước lịch sử.\n",
    "        num_series: số biến chuỗi (ví dụ: 2).\n",
    "        static_dim: số cột static.\n",
    "        latent_dim: kích thước không gian latent.\n",
    "        hidden_dim: kích thước tầng ẩn trong FC.\n",
    "        output_dim: số biến dự báo (2).\n",
    "        num_quantiles: số lượng quantile cần dự báo (ví dụ: [0.05, 0.50, 0.95] → 3).\n",
    "        \n",
    "        => Decoder sẽ xuất ra output_dim * num_quantiles giá trị.\n",
    "        \"\"\"\n",
    "        super(ConditionalQuantileVAE, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_series = num_series\n",
    "        self.static_dim = static_dim\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Encoder: input = flatten(x_seq) (window_size*num_series) concat x_cal (static_dim)\n",
    "        self.encoder_input_dim = window_size * num_series + static_dim\n",
    "        self.fc_enc = nn.Sequential(\n",
    "            nn.Linear(self.encoder_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu_z = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar_z = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder: input = [z; x_cal]\n",
    "        self.decoder_input_dim = latent_dim + static_dim\n",
    "        self.fc_dec = nn.Sequential(\n",
    "            nn.Linear(self.decoder_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Skip connection từ flatten(x_seq)\n",
    "        self.fc_skip = nn.Linear(window_size * num_series, hidden_dim)\n",
    "        \n",
    "        # Final head: xuất ra output_dim * num_quantiles (cho mỗi biến, các quantile)\n",
    "        self.final_fc = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim * num_quantiles)\n",
    "        )\n",
    "    \n",
    "    def encode(self, x_seq, x_cal):\n",
    "        batch_size = x_seq.size(0)\n",
    "        x_seq_flat = x_seq.view(batch_size, -1)  # (batch, window_size*num_series)\n",
    "        enc_input = torch.cat([x_seq_flat, x_cal], dim=1)  # (batch, encoder_input_dim)\n",
    "        h_enc = self.fc_enc(enc_input)  # (batch, hidden_dim)\n",
    "        mu_z = self.fc_mu_z(h_enc)      # (batch, latent_dim)\n",
    "        logvar_z = self.fc_logvar_z(h_enc)  # (batch, latent_dim)\n",
    "        return mu_z, logvar_z, x_seq_flat\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z, x_cal, skip_flat):\n",
    "        dec_input = torch.cat([z, x_cal], dim=1)  # (batch, decoder_input_dim)\n",
    "        h_dec = self.fc_dec(dec_input)  # (batch, hidden_dim)\n",
    "        skip_feat = self.fc_skip(skip_flat)  # (batch, hidden_dim)\n",
    "        combined = torch.cat([h_dec, skip_feat], dim=1)  # (batch, 2*hidden_dim)\n",
    "        out = self.final_fc(combined)  # (batch, output_dim*num_quantiles)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x_seq, x_cal):\n",
    "        mu_z, logvar_z, skip_flat = self.encode(x_seq, x_cal)\n",
    "        z = self.reparameterize(mu_z, logvar_z)\n",
    "        out = self.decode(z, x_cal, skip_flat)\n",
    "        return out, mu_z, logvar_z\n",
    "\n",
    "##########################################\n",
    "# Quantile Loss (Pinball Loss)\n",
    "##########################################\n",
    "def quantile_loss(y_pred, y_true, quantiles):\n",
    "    \"\"\"\n",
    "    y_pred: (batch, output_dim*num_quantiles) → reshape thành (batch, num_quantiles, output_dim)\n",
    "    y_true: (batch, output_dim)\n",
    "    quantiles: list hoặc array các quantile (ví dụ [0.05, 0.50, 0.95])\n",
    "    \"\"\"\n",
    "    batch_size, out_dim_times_q = y_pred.shape\n",
    "    num_quantiles = len(quantiles)\n",
    "    output_dim = out_dim_times_q // num_quantiles\n",
    "    y_pred = y_pred.view(batch_size, num_quantiles, output_dim)\n",
    "    loss = 0\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = y_true - y_pred[:, i, :]\n",
    "        loss += torch.max((q - 1) * errors, q * errors).unsqueeze(1)\n",
    "    loss = torch.mean(loss)\n",
    "    return loss\n",
    "\n",
    "def conditional_quantile_vae_loss(out, y_true, mu_z, logvar_z, quantiles, kl_weight=0.001):\n",
    "    q_loss = quantile_loss(out, y_true, quantiles)\n",
    "    kl_loss = -0.5 * torch.mean(1 + logvar_z - mu_z.pow(2) - logvar_z.exp())\n",
    "    return q_loss + kl_weight * kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "static_dim = 18\n",
    "num_series = 2\n",
    "\n",
    "quantiles = [0.05, 0.50, 0.95]  # Dự báo 3 quantiles\n",
    "\n",
    "latent_dim = 32\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "\n",
    "model = ConditionalQuantileVAE(window_size, num_series, static_dim,\n",
    "                                latent_dim=latent_dim, hidden_dim=hidden_dim,\n",
    "                                dropout=0.1, output_dim=output_dim, num_quantiles=len(quantiles))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "kl_weight = 0.001  # cố định"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated at epoch 1 with validation loss 0.3871\n",
      "Best model updated at epoch 2 with validation loss 0.3353\n",
      "Best model updated at epoch 3 with validation loss 0.2625\n",
      "Best model updated at epoch 4 with validation loss 0.2306\n",
      "Best model updated at epoch 5 with validation loss 0.2049\n",
      "Best model updated at epoch 6 with validation loss 0.1959\n",
      "Best model updated at epoch 8 with validation loss 0.1789\n",
      "Best model updated at epoch 9 with validation loss 0.1766\n",
      "Epoch [10/150], Train Loss: 0.1545, Val Loss: 0.1649, KL Weight: 0.000180\n",
      "Best model updated at epoch 10 with validation loss 0.1649\n",
      "Best model updated at epoch 12 with validation loss 0.1621\n",
      "Best model updated at epoch 13 with validation loss 0.1502\n",
      "Best model updated at epoch 16 with validation loss 0.1485\n",
      "Best model updated at epoch 17 with validation loss 0.1478\n",
      "Best model updated at epoch 18 with validation loss 0.1370\n",
      "Epoch [20/150], Train Loss: 0.1179, Val Loss: 0.1311, KL Weight: 0.000380\n",
      "Best model updated at epoch 20 with validation loss 0.1311\n",
      "Best model updated at epoch 26 with validation loss 0.1258\n",
      "Best model updated at epoch 27 with validation loss 0.1191\n",
      "Best model updated at epoch 29 with validation loss 0.1182\n",
      "Epoch [30/150], Train Loss: 0.1018, Val Loss: 0.1255, KL Weight: 0.000580\n",
      "Best model updated at epoch 31 with validation loss 0.1179\n",
      "Best model updated at epoch 33 with validation loss 0.1140\n",
      "Best model updated at epoch 35 with validation loss 0.1093\n",
      "Epoch [40/150], Train Loss: 0.0883, Val Loss: 0.1143, KL Weight: 0.000780\n",
      "Best model updated at epoch 42 with validation loss 0.1047\n",
      "Best model updated at epoch 43 with validation loss 0.1036\n",
      "Best model updated at epoch 44 with validation loss 0.1018\n",
      "Best model updated at epoch 47 with validation loss 0.1007\n",
      "Best model updated at epoch 49 with validation loss 0.0996\n",
      "Epoch [50/150], Train Loss: 0.0722, Val Loss: 0.1005, KL Weight: 0.000980\n",
      "Best model updated at epoch 54 with validation loss 0.0978\n",
      "Epoch [60/150], Train Loss: 0.0733, Val Loss: 0.0948, KL Weight: 0.001000\n",
      "Best model updated at epoch 60 with validation loss 0.0948\n",
      "Epoch [70/150], Train Loss: 0.0638, Val Loss: 0.0977, KL Weight: 0.001000\n",
      "Best model updated at epoch 72 with validation loss 0.0941\n",
      "Best model updated at epoch 78 with validation loss 0.0930\n",
      "Best model updated at epoch 79 with validation loss 0.0929\n",
      "Epoch [80/150], Train Loss: 0.0625, Val Loss: 0.0957, KL Weight: 0.001000\n",
      "Best model updated at epoch 82 with validation loss 0.0926\n",
      "Best model updated at epoch 84 with validation loss 0.0921\n",
      "Best model updated at epoch 89 with validation loss 0.0912\n",
      "Epoch [90/150], Train Loss: 0.0581, Val Loss: 0.0925, KL Weight: 0.001000\n",
      "Best model updated at epoch 99 with validation loss 0.0910\n",
      "Epoch [100/150], Train Loss: 0.0554, Val Loss: 0.0927, KL Weight: 0.001000\n",
      "Best model updated at epoch 102 with validation loss 0.0899\n",
      "Best model updated at epoch 107 with validation loss 0.0885\n",
      "Epoch [110/150], Train Loss: 0.0573, Val Loss: 0.0909, KL Weight: 0.001000\n",
      "Epoch [120/150], Train Loss: 0.0541, Val Loss: 0.0896, KL Weight: 0.001000\n",
      "Epoch [130/150], Train Loss: 0.0534, Val Loss: 0.0906, KL Weight: 0.001000\n",
      "Epoch [140/150], Train Loss: 0.0521, Val Loss: 0.0901, KL Weight: 0.001000\n",
      "Epoch [150/150], Train Loss: 0.0531, Val Loss: 0.0900, KL Weight: 0.001000\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    kl_weight = min(0.001, 0.001 * (epoch / 50))\n",
    "    for x_seq, x_cal, y in train_loader:\n",
    "        x_seq = x_seq.to(device)\n",
    "        x_cal = x_cal.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out, mu_z, logvar_z = model(x_seq, x_cal)\n",
    "        loss = conditional_quantile_vae_loss(out, y, mu_z, logvar_z, quantiles, kl_weight=kl_weight)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_seq.size(0)\n",
    "    epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_seq, x_cal, y in val_loader:\n",
    "            x_seq = x_seq.to(device)\n",
    "            x_cal = x_cal.to(device)\n",
    "            y = y.to(device)\n",
    "            out, mu_z, logvar_z = model(x_seq, x_cal)\n",
    "            loss = conditional_quantile_vae_loss(out, y, mu_z, logvar_z, quantiles, kl_weight=kl_weight)\n",
    "            running_val_loss += loss.item() * x_seq.size(0)\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    scheduler.step(epoch_val_loss)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, KL Weight: {kl_weight:.6f}\")\n",
    "    \n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': epoch_val_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, 'checkpoints/CQV.pth')\n",
    "        print(f\"Best model updated at epoch {epoch+1} with validation loss {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared: 0.9759\n",
      "Test MAPE: 0.2729\n",
      "Test RMSE: 114704.3984\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_actuals = []\n",
    "with torch.no_grad():\n",
    "    for x_seq, x_cal, y in test_loader:\n",
    "        x_seq = x_seq.to(device)\n",
    "        x_cal = x_cal.to(device)\n",
    "        y = y.to(device)\n",
    "        out, mu_z, logvar_z = model(x_seq, x_cal)\n",
    "        # Lấy quantile trung vị (0.50) làm point forecast\n",
    "        batch_size = out.size(0)\n",
    "        out = out.view(batch_size, len(quantiles), output_dim)\n",
    "        median_pred = out[:, 1, :]  # (batch, output_dim)\n",
    "        test_preds.append(median_pred.cpu().numpy())\n",
    "        test_actuals.append(y.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_actuals = np.concatenate(test_actuals, axis=0)\n",
    "\n",
    "# Inverse transform nếu cần (giả sử scaler đã được fit trên target)\n",
    "test_preds_inv = scaler.inverse_transform(test_preds)\n",
    "test_actuals_inv = scaler.inverse_transform(test_actuals)\n",
    "\n",
    "r2 = r2_score(test_actuals_inv, test_preds_inv)\n",
    "mape = mean_absolute_percentage_error(test_actuals_inv, test_preds_inv)\n",
    "rmse = np.sqrt(mean_squared_error(test_actuals_inv, test_preds_inv))\n",
    "print(f\"Test R-squared: {r2:.4f}\")\n",
    "print(f\"Test MAPE: {mape:.4f}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
