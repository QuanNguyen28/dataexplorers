{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from loader import train_loader, val_loader, test_loader, scaler\n",
    "from models.pft import ProbabilisticForecastTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distributional_vae_loss(out, y_true, mu_z, logvar_z, kl_weight=0.001):\n",
    "    # out: (batch, output_dim*2) -> tách ra μ_y và logvar_y\n",
    "    batch_size, out_dim2 = out.shape\n",
    "    output_dim = out_dim2 // 2\n",
    "    mu_y = out[:, :output_dim]\n",
    "    logvar_y = out[:, output_dim:]\n",
    "    \n",
    "    sigma_y = torch.exp(0.5 * logvar_y)\n",
    "    nll = 0.5 * (np.log(2 * np.pi) + logvar_y + ((y_true - mu_y)**2 / (sigma_y**2)))\n",
    "    nll = torch.mean(torch.sum(nll, dim=1))\n",
    "    \n",
    "    kl = -0.5 * torch.mean(1 + logvar_z - mu_z.pow(2) - logvar_z.exp())\n",
    "    \n",
    "    return nll + kl_weight * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProbabilisticForecastTransformer(\n",
    "\twindow_size=30, \n",
    "\tnum_series=2, \n",
    "\tstatic_dim=18,\n",
    "    latent_dim=32, \n",
    "\td_model=64, \n",
    "\tnhead=4, \n",
    "\tnum_layers=2,\n",
    "    hidden_dim=128, \n",
    "\tdropout=0.1, \n",
    "\toutput_dim=2\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "kl_start = 0.0\n",
    "kl_max = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model updated at epoch 1 with validation loss 1.6217\n",
      "Best model updated at epoch 2 with validation loss 1.1114\n",
      "Best model updated at epoch 3 with validation loss 0.8380\n",
      "Best model updated at epoch 5 with validation loss 0.6951\n",
      "Best model updated at epoch 6 with validation loss 0.6185\n",
      "Best model updated at epoch 7 with validation loss 0.6158\n",
      "Best model updated at epoch 8 with validation loss 0.3470\n",
      "Epoch [10/100], Train Loss: 0.2992, Val Loss: 0.2478, KL Weight: 0.000180\n",
      "Best model updated at epoch 10 with validation loss 0.2478\n",
      "Best model updated at epoch 11 with validation loss 0.2406\n",
      "Best model updated at epoch 12 with validation loss 0.1906\n",
      "Best model updated at epoch 13 with validation loss 0.1583\n",
      "Best model updated at epoch 15 with validation loss 0.0474\n",
      "Best model updated at epoch 16 with validation loss 0.0266\n",
      "Best model updated at epoch 18 with validation loss -0.0079\n",
      "Epoch [20/100], Train Loss: -0.2334, Val Loss: -0.0446, KL Weight: 0.000380\n",
      "Best model updated at epoch 20 with validation loss -0.0446\n",
      "Best model updated at epoch 22 with validation loss -0.1085\n",
      "Best model updated at epoch 23 with validation loss -0.1964\n",
      "Best model updated at epoch 24 with validation loss -0.2026\n",
      "Epoch [30/100], Train Loss: -0.3688, Val Loss: -0.1154, KL Weight: 0.000580\n",
      "Best model updated at epoch 31 with validation loss -0.2612\n",
      "Best model updated at epoch 32 with validation loss -0.3890\n",
      "Best model updated at epoch 38 with validation loss -0.4209\n",
      "Epoch [40/100], Train Loss: -0.7535, Val Loss: -0.4386, KL Weight: 0.000780\n",
      "Best model updated at epoch 40 with validation loss -0.4386\n",
      "Best model updated at epoch 45 with validation loss -0.5472\n",
      "Best model updated at epoch 47 with validation loss -0.6006\n",
      "Epoch [50/100], Train Loss: -0.9295, Val Loss: -0.5808, KL Weight: 0.000980\n",
      "Best model updated at epoch 51 with validation loss -0.6432\n",
      "Best model updated at epoch 56 with validation loss -0.6710\n",
      "Best model updated at epoch 57 with validation loss -0.7997\n",
      "Best model updated at epoch 58 with validation loss -0.8039\n",
      "Epoch [60/100], Train Loss: -1.0180, Val Loss: -0.7602, KL Weight: 0.001000\n",
      "Best model updated at epoch 62 with validation loss -0.8202\n",
      "Best model updated at epoch 63 with validation loss -0.8335\n",
      "Best model updated at epoch 64 with validation loss -0.8747\n",
      "Best model updated at epoch 66 with validation loss -0.9121\n",
      "Best model updated at epoch 68 with validation loss -0.9538\n",
      "Epoch [70/100], Train Loss: -1.1611, Val Loss: -0.8521, KL Weight: 0.001000\n",
      "Best model updated at epoch 74 with validation loss -1.0169\n",
      "Best model updated at epoch 75 with validation loss -1.0250\n",
      "Best model updated at epoch 76 with validation loss -1.2021\n",
      "Epoch [80/100], Train Loss: -1.2604, Val Loss: -1.1271, KL Weight: 0.001000\n",
      "Best model updated at epoch 83 with validation loss -1.2466\n",
      "Best model updated at epoch 84 with validation loss -1.2924\n",
      "Best model updated at epoch 86 with validation loss -1.3162\n",
      "Best model updated at epoch 87 with validation loss -1.3467\n",
      "Best model updated at epoch 88 with validation loss -1.4132\n",
      "Epoch [90/100], Train Loss: -1.5402, Val Loss: -1.3720, KL Weight: 0.001000\n",
      "Best model updated at epoch 91 with validation loss -1.4308\n",
      "Best model updated at epoch 98 with validation loss -1.4934\n",
      "Epoch [100/100], Train Loss: -1.6770, Val Loss: -1.5010, KL Weight: 0.001000\n",
      "Best model updated at epoch 100 with validation loss -1.5010\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# KL annealing: tăng kl_weight dần từ 0 đến 0.001\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    kl_weight = min(0.001, 0.001 * (epoch / 50))\n",
    "    for x_seq, x_cal, y in train_loader:\n",
    "        x_seq = x_seq.to(device)\n",
    "        x_cal = x_cal.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out, mu_z, logvar_z = model(x_seq, x_cal)\n",
    "        loss = distributional_vae_loss(out, y, mu_z, logvar_z, kl_weight=kl_weight)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * x_seq.size(0)\n",
    "    epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_seq, x_cal, y in val_loader:\n",
    "            x_seq = x_seq.to(device)\n",
    "            x_cal = x_cal.to(device)\n",
    "            y = y.to(device)\n",
    "            out, mu_z, logvar_z = model(x_seq, x_cal)\n",
    "            loss = distributional_vae_loss(out, y, mu_z, logvar_z, kl_weight=kl_weight)\n",
    "            running_val_loss += loss.item() * x_seq.size(0)\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    scheduler.step(epoch_val_loss)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, KL Weight: {kl_weight:.6f}\")\n",
    "    \n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': epoch_val_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, 'best_probabilistic_vae_checkpoint.pth')\n",
    "        print(f\"Best model updated at epoch {epoch+1} with validation loss {epoch_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared: 0.9682\n",
      "Test MAPE: 0.2565\n",
      "Test RMSE: 110592.9688\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_actuals = []\n",
    "with torch.no_grad():\n",
    "    for x_seq, x_cal, y in test_loader:\n",
    "        x_seq = x_seq.to(device)\n",
    "        x_cal = x_cal.to(device)\n",
    "        y = y.to(device)\n",
    "        out, mu_z, logvar_z = model(x_seq, x_cal)\n",
    "        # Lấy phần μ của dự báo (mu_y) từ output\n",
    "        out_dim2 = out.shape[1]\n",
    "        out_dim = out_dim2 // 2\n",
    "        mu_y = out[:, :out_dim]  # (batch, output_dim)\n",
    "        test_preds.append(mu_y.cpu().numpy())\n",
    "        test_actuals.append(y.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_actuals = np.concatenate(test_actuals, axis=0)\n",
    "\n",
    "# Giả sử bạn có scaler để inverse transform target\n",
    "test_preds_inv = scaler.inverse_transform(test_preds)\n",
    "test_actuals_inv = scaler.inverse_transform(test_actuals)\n",
    "\n",
    "r2 = r2_score(test_actuals_inv, test_preds_inv)\n",
    "mape = mean_absolute_percentage_error(test_actuals_inv, test_preds_inv)\n",
    "rmse = np.sqrt(mean_squared_error(test_actuals_inv, test_preds_inv))\n",
    "print(f\"Test R-squared: {r2:.4f}\")\n",
    "print(f\"Test MAPE: {mape:.4f}\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Units - R-squared: 0.9599\n",
      "Test Units - MAPE: 0.3017\n",
      "Test Units - RMSE: 25.8991\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá trên Units\n",
    "r2_units = r2_score(test_actuals_inv[:, 0], test_preds_inv[:, 0])\n",
    "mape_units = mean_absolute_percentage_error(test_actuals_inv[:, 0], test_preds_inv[:, 0])\n",
    "rmse_units = np.sqrt(mean_squared_error(test_actuals_inv[:, 0], test_preds_inv[:, 0]))\n",
    "\n",
    "print(f\"Test Units - R-squared: {r2_units:.4f}\")\n",
    "print(f\"Test Units - MAPE: {mape_units:.4f}\")\n",
    "print(f\"Test Units - RMSE: {rmse_units:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Revenue - R-squared: 0.9764\n",
      "Test Revenue - MAPE: 0.2112\n",
      "Test Revenue - RMSE: 156402.0625\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá trên Revenue\n",
    "r2_revenue = r2_score(test_actuals_inv[:, 1], test_preds_inv[:, 1])\n",
    "mape_revenue = mean_absolute_percentage_error(test_actuals_inv[:, 1], test_preds_inv[:, 1])\n",
    "rmse_revenue = np.sqrt(mean_squared_error(test_actuals_inv[:, 1], test_preds_inv[:, 1]))\n",
    "\n",
    "print(f\"Test Revenue - R-squared: {r2_revenue:.4f}\")\n",
    "print(f\"Test Revenue - MAPE: {mape_revenue:.4f}\")\n",
    "print(f\"Test Revenue - RMSE: {rmse_revenue:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
